{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPI9R41ejSR2uR7awncDKf5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rraghavkaushik/Image-to-Image-Translation/blob/main/Image_to_Image_Translation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Xpy5pnuFFfEP"
      },
      "outputs": [],
      "source": [
        "import numpy\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.initializers import RandomNormal\n",
        "from keras.optimizers import Adam\n",
        "from keras.models import Model\n",
        "from keras.layers import Input\n",
        "from keras.layers import Conv2D, LeakyReLU, Activation, Concatenate, Dropout, BatchNormalization, Conv2DTranspose"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def discriminator(img_size):\n",
        "  wt = RandomNormal(stddev = 0.02)\n",
        "  src_img = Input(shape = img_size)\n",
        "  target_img = Input(shape = img_size)\n",
        "  ''' concatenating channel wise'''\n",
        "  conc_img = Concatenate()([src_img, target_img])\n",
        "\n",
        "  ''' Discriminator architechture described in the paper :\n",
        "    C64-C128-C256-C512\n",
        "    After the last layer, a convolution is applied to map to\n",
        "    a 1-dimensional output, followed by a Sigmoid function.\n",
        "    As an exception to the above notation, BatchNorm is not\n",
        "    applied to the first C64 layer. All ReLUs are leaky, with\n",
        "    slope 0.2.'''\n",
        "\n",
        "\n",
        "  l = Conv2D(64, (4, 4), strides = (2, 2), padding = 'same', kernel_initializer = wt)(conc_img)\n",
        "  l = LeakyReLU(alpha = 0.2)(l)\n",
        "\n",
        "  l = Conv2D(128, (4, 4), strides = (2, 2), padding = 'same', kernel_initializer = wt)(conc_img)\n",
        "  l = BatchNormalization()(l)\n",
        "  l = LeakyReLU(alpha = 0.2)(l)\n",
        "\n",
        "  l = Conv2D(256, (4, 4), strides = (2, 2), padding = 'same', kernel_initializer = wt)(conc_img)\n",
        "  l = BatchNormalization()(l)\n",
        "  l = LeakyReLU(alpha = 0.2)(l)\n",
        "\n",
        "  l = Conv2D(512, (4, 4), padding = 'same', kernel_initializer = wt)(l)\n",
        "  l = BatchNormalization()(l)\n",
        "  l = LeakyReLU(alpha = 0.2)(l)\n",
        "\n",
        "  l = Conv2D(1, (4, 4), padding = 'same', kernel_initializer = wt)(l)\n",
        "  output = Activation('sigmoid')(l)\n",
        "\n",
        "  model = Model(inputs = [src_img, target_img], outputs = output)\n",
        "  model.summary()\n",
        "  model.compile(loss = 'binary_crossentropy', optimizer = Adam(lr = 0.0002, beta_1 = 0.5), metrics = ['accuracy'])\n",
        "  return model\n"
      ],
      "metadata": {
        "id": "qK5WZ6mPFmM7"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1MnyP84fWk5N"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}